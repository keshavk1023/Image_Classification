{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using TensorFlow\n",
    "In this notebook, we will work on an image classification problem using TensorFlow and Keras. We will demonstrate data augmentation, model building, and training. Additionally, we will visualize the training process, evaluate the model, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import_libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Preprocess\n",
    "In this step, we will load the image data from the directory and apply data augmentation using the ImageDataGenerator class. We will also divide the data into training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the training and testing datasets\n",
    "train_data_dir = '/path/to/train'\n",
    "test_data_dir = '/path/to/test'\n",
    "\n",
    "# Image Data Generator with augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Some Sample Images\n",
    "Let's visualize some of the images from the dataset after augmentation to ensure everything is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "visualize_samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images from the training data\n",
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(sample_images[i])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "We will create a Convolutional Neural Network (CNN) with multiple layers and an output layer corresponding to the number of classes. The model will be compiled using the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "model_architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add dense layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",  # Assuming 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We will now train the model using the training data and validate it using the validation data. Early stopping is applied to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "train_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Now, let's evaluate the model's performance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation data\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Results\n",
    "We will plot the training and validation accuracy and loss to visualize the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "plot_training_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Finally, we will save the model to disk so that it can be used later for inference or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('image_classification_model.h5')\n",
    "print('Model saved!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we successfully created and trained an image classification model using TensorFlow and Keras. The model was evaluated, visualized, and saved for future use. You can now deploy the model for image classification tasks or further fine-tune it for your specific use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
